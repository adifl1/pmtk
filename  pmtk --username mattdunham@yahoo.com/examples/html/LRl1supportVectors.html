
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN">
<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      -->
      <title>Logistic Regression: L1 "Support Vectors"</title>
      <meta name="generator" content="MATLAB 7.6">
      <meta name="date" content="2008-10-21">
      <meta name="m-file" content="LRl1supportVectors"><style>

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head>
   <body>
      <div class="content">
         <h1>Logistic Regression: L1 "Support Vectors"</h1>
         <introduction>
            <p>In this example, we fit a logistic regression model to synthetic data using an RBF expansion and an L1 regularizer. We visualize
               the "support vectors", i.e. the examples corresponding to non-zero weights.
            </p>
         </introduction>
         <h2>Contents</h2>
         <div>
            <ul>
               <li><a href="#1">Load the Data</a></li>
               <li><a href="#2">Create the Data Transformer</a></li>
               <li><a href="#3">Create the Model</a></li>
               <li><a href="#4">Fit the Model</a></li>
               <li><a href="#5">Inspect the Parameters</a></li>
               <li><a href="#6">Predict</a></li>
               <li><a href="#8">Plot</a></li>
            </ul>
         </div>
         <h2>Load the Data<a name="1"></a></h2>
         <p>Our synthetic data consists of 100 2D examples from two different classes, 1 and 2.</p><pre class="codeinput">load <span class="string">synthetic2DdataSmall</span>
</pre><h2>Create the Data Transformer<a name="2"></a></h2>
         <p>As in our previous example, we create transformer objects to preprocess our data and perform the RBF expansion.</p><pre class="codeinput">sigma2 = 1;          <span class="comment">% kernel bandwidth</span>
T = chainTransformer({standardizeTransformer(false)      ,<span class="keyword">...</span>
                      kernelTransformer(<span class="string">'rbf'</span>,sigma2)} );
</pre><h2>Create the Model<a name="3"></a></h2>
         <p>We create a new model by calling the constructor.</p><pre class="codeinput">model = multinomLogregDist(<span class="string">'nclasses'</span>,2, <span class="string">'transformer'</span>, T);
</pre><h2>Fit the Model<a name="4"></a></h2>
         <p>This time we use an L1 sparsity promoting prior.</p><pre class="codeinput">lambda = 0.001;                                              <span class="comment">% L1 regularizer</span>
model = fit(model,<span class="string">'prior'</span>,<span class="string">'l1'</span>,<span class="string">'lambda'</span>,lambda,<span class="string">'X'</span>,X,<span class="string">'y'</span>,Y);
</pre><h2>Inspect the Parameters<a name="5"></a></h2>
         <p>We now inspect the weight vector and find the training examples that correspond to the non-zero weights. We indicate these
            with circles on the figure.
         </p><pre class="codeinput">supportVectors = X(model.w ~= 0,:);
</pre><h2>Predict<a name="6"></a></h2>
         <p>We will plot the decision boundary: the points that are equally likely to belong to each class. To do so, we must predict
            the class labels of a grid of points as in the previous example.
         </p><pre class="codeinput">[X1grid, X2grid] = meshgrid(0:0.01:1,0:0.01:1);
[nrows,ncols] = size(X1grid);
testData = [X1grid(:),X2grid(:)];
</pre><p>We extract the probabilities of each test point belonging to class 1 and reshape the vector for plotting purposes.</p><pre class="codeinput">pred = predict(model,testData);   <span class="comment">% pred is an object - a discrete distribution</span>
pclass1 = pred.probs(:,1);
probGrid = reshape(pclass1,nrows,ncols);
</pre><h2>Plot<a name="8"></a></h2><pre class="codeinput">figure;
plot(X(Y==1,1),X(Y==1,2),<span class="string">'xr'</span>,<span class="string">'MarkerSize'</span>,7,<span class="string">'LineWidth'</span>,1.5); hold <span class="string">on</span>;
plot(X(Y==2,1),X(Y==2,2),<span class="string">'xb'</span>,<span class="string">'MarkerSize'</span>,7,<span class="string">'LineWidth'</span>,1.5);
set(gca,<span class="string">'XTick'</span>,0:0.5:1,<span class="string">'YTick'</span>,0:0.5:1);
hold <span class="string">on</span>;
plot(supportVectors(:,1),supportVectors(:,2),<span class="string">'ok'</span>,<span class="string">'MarkerSize'</span>,10,<span class="string">'LineWidth'</span>,2)
contour(X1grid,X2grid,probGrid,<span class="string">'LineColor'</span>,<span class="string">'k'</span>,<span class="string">'LevelStep'</span>,0.5,<span class="string">'LineWidth'</span>,2);
title(<span class="string">'L1 "Support Vectors"'</span>);
</pre><img vspace="5" hspace="5" src="LRl1supportVectors_01.png"> <p class="footer"><br>
            Published with MATLAB&reg; 7.6<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Logistic Regression: L1 "Support Vectors" 
% In this example, we fit a logistic regression model to synthetic data using an
% RBF expansion and an L1 regularizer. We visualize the "support vectors", i.e.
% the examples corresponding to non-zero weights. 
%
%% Load the Data
% Our synthetic data consists of 100 2D examples from two different classes, 1
% and 2. 
load synthetic2DdataSmall
%% Create the Data Transformer
% As in our previous example, we create transformer objects to preprocess our
% data and perform the RBF expansion. 
sigma2 = 1;          % kernel bandwidth
T = chainTransformer({standardizeTransformer(false)      ,...
                      kernelTransformer('rbf',sigma2)} );
%% Create the Model
% We create a new model by calling the constructor. 
model = multinomLogregDist('nclasses',2, 'transformer', T);
%% Fit the Model
% This time we use an L1 sparsity promoting prior. 
lambda = 0.001;                                              % L1 regularizer
model = fit(model,'prior','l1','lambda',lambda,'X',X,'y',Y);
%% Inspect the Parameters
% We now inspect the weight vector and find the training examples that
% correspond to the non-zero weights. We indicate these with circles on the
% figure.
supportVectors = X(model.w ~= 0,:);
%% Predict
% We will plot the decision boundary: the points that are equally likely to
% belong to each class. To do so, we must predict the class labels of a grid of
% points as in the previous example. 
[X1grid, X2grid] = meshgrid(0:0.01:1,0:0.01:1);
[nrows,ncols] = size(X1grid);
testData = [X1grid(:),X2grid(:)];
%%
% We extract the probabilities of each test point belonging to class 1
% and reshape the vector for plotting purposes. 
pred = predict(model,testData);   % pred is an object - a discrete distribution
pclass1 = pred.probs(:,1);                   
probGrid = reshape(pclass1,nrows,ncols);
%% Plot 
figure;
plot(X(Y==1,1),X(Y==1,2),'xr','MarkerSize',7,'LineWidth',1.5); hold on;
plot(X(Y==2,1),X(Y==2,2),'xb','MarkerSize',7,'LineWidth',1.5);
set(gca,'XTick',0:0.5:1,'YTick',0:0.5:1);
hold on;
plot(supportVectors(:,1),supportVectors(:,2),'ok','MarkerSize',10,'LineWidth',2)
contour(X1grid,X2grid,probGrid,'LineColor','k','LevelStep',0.5,'LineWidth',2);
title('L1 "Support Vectors"');
%%
##### SOURCE END #####
-->
   </body>
</html>