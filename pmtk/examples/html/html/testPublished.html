
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN">
<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      -->
      <title>testPublished</title>
      <meta name="generator" content="MATLAB 7.6">
      <meta name="date" content="2008-10-25">
      <meta name="m-file" content="testPublished"><style>

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head>
   <body>
      <div class="content"><pre class="codeinput"><span class="comment">% specified method.</span>
<span class="comment">%</span>
<span class="comment">% FORMAT:</span>
<span class="comment">%          pred = predict(model, 'name1', val1, 'name2', val2, ...)</span>
<span class="comment">%</span>
<span class="comment">% INPUT:</span>
<span class="comment">%</span>
<span class="comment">% 'X'      The test data: X(i,:) is the ith case</span>
<span class="comment">%</span>
<span class="comment">% 'w'      (1) A matrix of weights of size</span>
<span class="comment">%              ndimensions-by-(nclasses-1) representing the MAP</span>
<span class="comment">%              estimate of the posterior p(w|D)</span>
<span class="comment">%</span>
<span class="comment">%          OR</span>
<span class="comment">%</span>
<span class="comment">%          (2) a mvnDist object representing the laplace</span>
<span class="comment">%              approximation to the posterior p(w|D)</span>
<span class="comment">%</span>
<span class="comment">%          If not set, the value stored in this object is</span>
<span class="comment">%          used instead, in particular: obj.w for case 1 and</span>
<span class="comment">%          obj.posteriorW for case 2</span>
<span class="comment">%</span>
<span class="comment">% 'method' {['plugin'] | 'mc' | 'integral'}</span>
<span class="comment">%</span>
<span class="comment">%          The method to use:</span>
<span class="comment">%</span>
<span class="comment">%          'mc' is only available if w is an mvnDist object or if w was</span>
<span class="comment">%          not specified and obj.posteriorW was set during the</span>
<span class="comment">%          fitting of this object, (which occurs when the prior is</span>
<span class="comment">%          set to 'L2').</span>
<span class="comment">%</span>
<span class="comment">%          'integral' uses a closed form approximation to the</span>
<span class="comment">%          posterior predictive distribution but is only available</span>
<span class="comment">%          in the 2 class case. Otherwise, the same conditions for</span>
<span class="comment">%          'mc' apply</span>
<span class="comment">%</span>
<span class="comment">% nsamples [1000] The number of Monte Carlo samples to perform. Only</span>
<span class="comment">%                 used when method = 'mc'</span>
<span class="comment">%</span>
<span class="comment">% OUTPUT:</span>
<span class="comment">%</span>
<span class="comment">% pred    - is a series of discrete distributions over class labels,</span>
<span class="comment">%           one for each test example X(i,:). All of these are</span>
<span class="comment">%           represented in a single discreteDist object such that</span>
<span class="comment">%           pred.probs(i,c) is the probability that example i</span>
<span class="comment">%           belongs to class c.</span>
<span class="comment">%</span>
<span class="comment">% samples -  A 3D matrix such that samples(i,c,s) = probability that</span>
<span class="comment">%            example i belongs to class c according to sample s. If</span>
<span class="comment">%            method is not 'mc', s = 1 and samples = pred.probs</span>
    [X,w,method,nsamples] = process_options(varargin,<span class="string">'X'</span>,[],<span class="string">'w'</span>,[],<span class="string">'method'</span>,<span class="string">'plugin'</span>,<span class="string">'nsamples'</span>,1000);
    <span class="keyword">if</span> ~isempty(obj.transformer)
        X = test(obj.transformer, X);
    <span class="keyword">end</span>

    <span class="keyword">switch</span> method

        <span class="keyword">case</span> <span class="string">'plugin'</span>
            <span class="keyword">if</span>(isempty(w)), w = obj.w; <span class="keyword">end</span>
            <span class="keyword">if</span>(isempty(w)),error(<span class="string">'Call fit() first or specify w'</span>);<span class="keyword">end</span>
            P = multiSigmoid(X,w);
            pred = discreteDist(P);
            samples = pred.probs;
        <span class="keyword">case</span> <span class="string">'mc'</span>
            w = checkW(w);
            Wsamples = sample(w,nsamples);
            samples = zeros(size(X,1),obj.nclasses,nsamples);
            <span class="keyword">for</span> s=1:nsamples
                samples(:,:,s) = multiSigmoid(X,Wsamples(s,:)');
            <span class="keyword">end</span>
            pred = discreteDist(mean(samples,3));
        <span class="keyword">case</span> <span class="string">'integral'</span>
            <span class="keyword">if</span>(obj.nclasses ~=2),error(<span class="string">'This method is only available in the 2 class case'</span>);                    <span class="keyword">end</span>
            w = checkW(w);
            p = sigmoidTimesGauss(X, w.mu(:), w.Sigma);
            pred = discreteDist([p,1-p]);
        <span class="keyword">otherwise</span>
            error(<span class="string">'%s is an unsupported prediction method'</span>,method);

    <span class="keyword">end</span>
            <span class="keyword">function</span> w = checkW(w)
                <span class="keyword">if</span>(isempty(w)),w = obj.posteriorW;<span class="keyword">end</span>
                <span class="keyword">if</span>(isempty(w)),error(<span class="string">'Call fit() first with an L2 prior or specify an mvnDist object for w representing p(w|D)'</span>);<span class="keyword">end</span>
                <span class="keyword">if</span>(~isa(w,<span class="string">'mvnDist'</span>)),error(<span class="string">'w must be an mvnDist object for this method'</span>);<span class="keyword">end</span>
            <span class="keyword">end</span>

<span class="keyword">end</span>

<span class="keyword">function</span> p = logprob(obj, X, y)
<span class="comment">% p(i) = log p(y(i) | X(i,:), obj.w), y(i) in 1...C</span>
    pred = predict(obj,<span class="string">'X'</span>,X,<span class="string">'method'</span>,<span class="string">'plugin'</span>);
    P = pred.probs;
    Y = oneOfK(y, obj.nclasses);
    p =  sum(sum(Y.*log(P)));
<span class="keyword">end</span>




ods(Access = <span class="string">'protected'</span>)

<span class="keyword">function</span> obj = fitL1(obj,X,Y1,lambda,method,offsetAdded)
<span class="comment">% Fit using the specified L1 regularizer, lambda via the specified method.</span>
    [n,d] = size(X);                                <span class="comment">%#ok</span>

    lambdaVec = lambda*ones(d,obj.nclasses-1);
    <span class="keyword">if</span>(offsetAdded),lambdaVec(:,1) = 0;<span class="keyword">end</span>
    lambdaVec = lambdaVec(:);
    options.verbose = false;
    optfunc = [];
    <span class="keyword">switch</span> lower(method)
        <span class="keyword">case</span> <span class="string">'iteratedridge'</span>
            optfunc = @L1GeneralIteratedRige;
        <span class="keyword">case</span> <span class="string">'projection'</span>
            optfunc = @L1GeneralProjection;
        <span class="keyword">case</span> <span class="string">'grafting'</span>
            optfunc = @L1GeneralGrafting;
        <span class="keyword">case</span> <span class="string">'orthantwise'</span>
            optfunc = @L1GeneralOrthantWist;
        <span class="keyword">case</span> <span class="string">'pdlb'</span>
            optfunc = @L1GeneralPrimalDualLogBarrier;
        <span class="keyword">case</span> <span class="string">'sequentialqp'</span>
            optfunc = @L1GeneralSequentialQuadraticProgramming;
        <span class="keyword">case</span> <span class="string">'subgradient'</span>
            optfunc = @L1GeneralSubGradient;
        <span class="keyword">case</span> <span class="string">'unconstrainedapx'</span>
            optfunc = @L1GeneralUnconstrainedApx;
        <span class="keyword">case</span> <span class="string">'unconstrainedapxsub'</span>
           optfunc = @L1GeneralUnconstrainedApx_sub;
        <span class="keyword">case</span> <span class="string">'boundoptrelaxed'</span>
            <span class="keyword">if</span>(offsetAdded),warning(<span class="string">'logregDist:offset'</span>,<span class="string">'currently penalizes offset weight'</span>),<span class="keyword">end</span>
            [obj.w,output] =  compileAndRun(<span class="string">'boundOptL1overrelaxed'</span>,X, Y1, lambda);
            output.ftrace = output.ftrace(output.ftrace ~= -1);
        <span class="keyword">case</span> <span class="string">'boundoptstepwise'</span>
            <span class="keyword">if</span>(offsetAdded),warning(<span class="string">'logregDist:offset'</span>,<span class="string">'currently penalizes offset weight'</span>),<span class="keyword">end</span>
            [obj.w, output] = compileAndRun(<span class="string">'boundOptL1Stepwise'</span>,X, Y1, lambda);
            output.ftrace = output.ftrace(output.ftrace ~= -1);
        <span class="keyword">otherwise</span>
            optfunc = @L1GeneralProjection;
    <span class="keyword">end</span>
    <span class="keyword">if</span>(~isempty(optfunc))
        obj.w = optfunc(@multinomLogregNLLGradHessL2,zeros(d*(obj.nclasses-1),1),lambdaVec,options,X,Y1,0,false);
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> [obj,output] = fitL2(obj,X,Y1,lambda,method,offsetAdded)
<span class="comment">% Fit using the specified L1 regularizer, lambda via the specified method.</span>
   [n,d] = size(X);                                                         <span class="comment">%#ok</span>
    <span class="keyword">switch</span> lower(method)
        <span class="keyword">case</span> <span class="string">'boundoptrelaxed'</span>
            <span class="keyword">if</span>(offsetAdded),warning(<span class="string">'logregDist:offset'</span>,<span class="string">'currently penalizes offset weight'</span>),<span class="keyword">end</span>
            [obj.w, output] = compileAndRun(<span class="string">'boundOptL2overrelaxed'</span>,X, Y1, lambda);
            output.ftrace = output.ftrace(output.ftrace ~= -1);
        <span class="keyword">case</span> <span class="string">'boundoptstepwise'</span>
            <span class="keyword">if</span>(offsetAdded),warning(<span class="string">'logregDist:offset'</span>,<span class="string">'currently penalizes offset weight'</span>),<span class="keyword">end</span>
            [obj.w, output] = compileAndRun(<span class="string">'boundOptL2Stepwise'</span>,X, Y1, lambda);
            output.ftrace = output.ftrace(output.ftrace ~= -1);
        <span class="keyword">otherwise</span>
            <span class="keyword">if</span>(strcmpi(method,<span class="string">'default'</span>))
                method = <span class="string">'lbfgs'</span>;
            <span class="keyword">end</span>
            options.Method = method;
            options.Display = 0;
            winit = zeros(d*(obj.nclasses-1),1);
            [obj.w, f, exitflag, output] = minFunc(@multinomLogregNLLGradHessL2, winit, options, X, Y1, lambda,offsetAdded); <span class="comment">%#ok</span>
    <span class="keyword">end</span>
    <span class="keyword">try</span>
        wMAP = obj.w;
        [nll, g, H] = multinomLogregNLLGradHessL2(wMAP, X, Y1, lambda); <span class="comment">%#ok  H = hessian of neg log lik</span>
        C = inv(H);
        obj.posteriorW = mvnDist(wMAP, C); <span class="comment">%C  = inv Hessian(neg log lik)</span>
    <span class="keyword">catch</span>
        warning(<span class="string">'logregDist:Laplace'</span>,<span class="string">'obj.posteriorW not set: could not invert the Hessian of the log-posterior.'</span>);
    <span class="keyword">end</span>
<span class="keyword">end</span>





emos
ods(Static = true)

<span class="keyword">function</span> test()
<span class="comment">% check functions are syntactically correct</span>
    n = 10; d = 3; C = 2;
    X = randn(n,d );
    y = sampleDiscrete((1/C)*ones(1,C), n, 1);
    mL2 = logregDist(<span class="string">'nclasses'</span>, C);
    mL2 = fit(mL2, <span class="string">'X'</span>, X, <span class="string">'y'</span>, y);
    predMAPL2 = predict(mL2, <span class="string">'X'</span>,X);                                                <span class="comment">%#ok</span>
    [predMCL2,samplesL2]  = predict(mL2,<span class="string">'X'</span>,X,<span class="string">'method'</span>,<span class="string">'mc'</span>,<span class="string">'nsamples'</span>,2000);       <span class="comment">%#ok</span>
    predExactL2 = predict(mL2,<span class="string">'X'</span>,X,<span class="string">'method'</span>,<span class="string">'integral'</span>);                           <span class="comment">%#ok</span>
    llL2 = logprob(mL1, X, y);                                                      <span class="comment">%#ok</span>
</pre><pre class="codeoutput">Error: File: C:\PMTK\examples\html\testPublished.m Line: 81 Column: 13
Function definitions are not permitted at the prompt or in scripts.

</pre><pre class="codeinput">    mL1 = logregDist(<span class="string">'nclasses'</span>,C);
    mL1 = fit(mL1,<span class="string">'X'</span>,X,<span class="string">'y'</span>,y,<span class="string">'prior'</span>,<span class="string">'L1'</span>,<span class="string">'lambda'</span>,0.1);
    pred = predict(mL1,<span class="string">'X'</span>,X);                                                      <span class="comment">%#ok</span>
<span class="keyword">end</span>

<span class="keyword">function</span> demoCrabs()
<span class="comment">% Here we fit an L2 regularized logistic regression model to the crabs</span>
<span class="comment">% data set and predict using three methods: MAP plugin approx, Monte</span>
<span class="comment">% Carlo approx, and using a closed form approximation to the posterior</span>
<span class="comment">% predictive.</span>
    [Xtrain, ytrain, Xtest, ytest] = makeCrabs;
    sigma2 = 32/5;
    T = chainTransformer({standardizeTransformer(false), kernelTransformer(<span class="string">'rbf'</span>, sigma2)});
    m = logregDist(<span class="string">'nclasses'</span>,2, <span class="string">'transformer'</span>, T);
    lambda = 1e-3;
    m = fit(m, <span class="string">'X'</span>, Xtrain, <span class="string">'y'</span>, ytrain, <span class="string">'lambda'</span>, lambda,<span class="string">'prior'</span>,<span class="string">'l2'</span>);
    Pmap   = predict(m,<span class="string">'X'</span>,Xtest,<span class="string">'method'</span>,<span class="string">'plugin'</span>);
    Pmc    = predict(m,<span class="string">'X'</span>,Xtest,<span class="string">'method'</span>,<span class="string">'mc'</span>);
    Pexact = predict(m,<span class="string">'X'</span>,Xtest,<span class="string">'method'</span>,<span class="string">'integral'</span>);
    nerrsMAP   = sum(mode(Pmap)' ~= ytest)
    nerrsMC    = sum(mode(Pmc)' ~= ytest)
    nerrsExact = sum(mode(Pexact)' ~= ytest)
</pre><p class="footer"><br>
            Published with MATLAB&reg; 7.6<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
% specified method.
%
% FORMAT:
%          pred = predict(model, 'name1', val1, 'name2', val2, ...)
%
% INPUT:
%
% 'X'      The test data: X(i,:) is the ith case
%
% 'w'      (1) A matrix of weights of size
%              ndimensions-by-(nclasses-1) representing the MAP
%              estimate of the posterior p(w|D)
%
%          OR
%
%          (2) a mvnDist object representing the laplace
%              approximation to the posterior p(w|D)
%
%          If not set, the value stored in this object is
%          used instead, in particular: obj.w for case 1 and
%          obj.posteriorW for case 2
%
% 'method' {['plugin'] | 'mc' | 'integral'}
%
%          The method to use:
%
%          'mc' is only available if w is an mvnDist object or if w was
%          not specified and obj.posteriorW was set during the
%          fitting of this object, (which occurs when the prior is
%          set to 'L2').
%
%          'integral' uses a closed form approximation to the
%          posterior predictive distribution but is only available
%          in the 2 class case. Otherwise, the same conditions for
%          'mc' apply
%
% nsamples [1000] The number of Monte Carlo samples to perform. Only
%                 used when method = 'mc'
%
% OUTPUT:
%
% pred    - is a series of discrete distributions over class labels,
%           one for each test example X(i,:). All of these are
%           represented in a single discreteDist object such that
%           pred.probs(i,c) is the probability that example i
%           belongs to class c.
%
% samples -  A 3D matrix such that samples(i,c,s) = probability that
%            example i belongs to class c according to sample s. If
%            method is not 'mc', s = 1 and samples = pred.probs
    [X,w,method,nsamples] = process_options(varargin,'X',[],'w',[],'method','plugin','nsamples',1000);
    if ~isempty(obj.transformer)
        X = test(obj.transformer, X);
    end
    
    switch method
        
        case 'plugin'
            if(isempty(w)), w = obj.w; end
            if(isempty(w)),error('Call fit() first or specify w');end
            P = multiSigmoid(X,w);
            pred = discreteDist(P);
            samples = pred.probs;
        case 'mc'
            w = checkW(w);
            Wsamples = sample(w,nsamples);
            samples = zeros(size(X,1),obj.nclasses,nsamples);
            for s=1:nsamples
                samples(:,:,s) = multiSigmoid(X,Wsamples(s,:)');
            end
            pred = discreteDist(mean(samples,3));
        case 'integral'
            if(obj.nclasses ~=2),error('This method is only available in the 2 class case');                    end
            w = checkW(w);
            p = sigmoidTimesGauss(X, w.mu(:), w.Sigma);
            pred = discreteDist([p,1-p]);
        otherwise
            error('%s is an unsupported prediction method',method);
          
    end
            function w = checkW(w)
                if(isempty(w)),w = obj.posteriorW;end
                if(isempty(w)),error('Call fit() first with an L2 prior or specify an mvnDist object for w representing p(w|D)');end
                if(~isa(w,'mvnDist')),error('w must be an mvnDist object for this method');end
            end
    
end

function p = logprob(obj, X, y)
% p(i) = log p(y(i) | X(i,:), obj.w), y(i) in 1...C
    pred = predict(obj,'X',X,'method','plugin');
    P = pred.probs;
    Y = oneOfK(y, obj.nclasses);
    p =  sum(sum(Y.*log(P)));
end




ods(Access = 'protected')

function obj = fitL1(obj,X,Y1,lambda,method,offsetAdded)
% Fit using the specified L1 regularizer, lambda via the specified method.
    [n,d] = size(X);                                %#ok
    
    lambdaVec = lambda*ones(d,obj.nclasses-1);
    if(offsetAdded),lambdaVec(:,1) = 0;end
    lambdaVec = lambdaVec(:);
    options.verbose = false;
    optfunc = [];
    switch lower(method)
        case 'iteratedridge'
            optfunc = @L1GeneralIteratedRige;
        case 'projection'
            optfunc = @L1GeneralProjection;
        case 'grafting'
            optfunc = @L1GeneralGrafting;
        case 'orthantwise'
            optfunc = @L1GeneralOrthantWist;
        case 'pdlb'
            optfunc = @L1GeneralPrimalDualLogBarrier;
        case 'sequentialqp'
            optfunc = @L1GeneralSequentialQuadraticProgramming;
        case 'subgradient'
            optfunc = @L1GeneralSubGradient;
        case 'unconstrainedapx'
            optfunc = @L1GeneralUnconstrainedApx;
        case 'unconstrainedapxsub'
           optfunc = @L1GeneralUnconstrainedApx_sub;
        case 'boundoptrelaxed'
            if(offsetAdded),warning('logregDist:offset','currently penalizes offset weight'),end
            [obj.w,output] =  compileAndRun('boundOptL1overrelaxed',X, Y1, lambda);
            output.ftrace = output.ftrace(output.ftrace ~= -1);
        case 'boundoptstepwise'
            if(offsetAdded),warning('logregDist:offset','currently penalizes offset weight'),end
            [obj.w, output] = compileAndRun('boundOptL1Stepwise',X, Y1, lambda);
            output.ftrace = output.ftrace(output.ftrace ~= -1);    
        otherwise
            optfunc = @L1GeneralProjection;
    end
    if(~isempty(optfunc))
        obj.w = optfunc(@multinomLogregNLLGradHessL2,zeros(d*(obj.nclasses-1),1),lambdaVec,options,X,Y1,0,false);
    end
end

function [obj,output] = fitL2(obj,X,Y1,lambda,method,offsetAdded)
% Fit using the specified L1 regularizer, lambda via the specified method.
   [n,d] = size(X);                                                         %#ok
    switch lower(method)
        case 'boundoptrelaxed'
            if(offsetAdded),warning('logregDist:offset','currently penalizes offset weight'),end
            [obj.w, output] = compileAndRun('boundOptL2overrelaxed',X, Y1, lambda);
            output.ftrace = output.ftrace(output.ftrace ~= -1);
        case 'boundoptstepwise'
            if(offsetAdded),warning('logregDist:offset','currently penalizes offset weight'),end
            [obj.w, output] = compileAndRun('boundOptL2Stepwise',X, Y1, lambda);
            output.ftrace = output.ftrace(output.ftrace ~= -1);
        otherwise
            if(strcmpi(method,'default'))
                method = 'lbfgs';
            end
            options.Method = method;
            options.Display = 0;
            winit = zeros(d*(obj.nclasses-1),1);
            [obj.w, f, exitflag, output] = minFunc(@multinomLogregNLLGradHessL2, winit, options, X, Y1, lambda,offsetAdded); %#ok
    end
    try
        wMAP = obj.w;
        [nll, g, H] = multinomLogregNLLGradHessL2(wMAP, X, Y1, lambda); %#ok  H = hessian of neg log lik    
        C = inv(H);
        obj.posteriorW = mvnDist(wMAP, C); %C  = inv Hessian(neg log lik)
    catch
        warning('logregDist:Laplace','obj.posteriorW not set: could not invert the Hessian of the log-posterior.');
    end
end





emos
ods(Static = true)

function test()
% check functions are syntactically correct
    n = 10; d = 3; C = 2;
    X = randn(n,d );
    y = sampleDiscrete((1/C)*ones(1,C), n, 1);
    mL2 = logregDist('nclasses', C);
    mL2 = fit(mL2, 'X', X, 'y', y);
    predMAPL2 = predict(mL2, 'X',X);                                                %#ok
    [predMCL2,samplesL2]  = predict(mL2,'X',X,'method','mc','nsamples',2000);       %#ok
    predExactL2 = predict(mL2,'X',X,'method','integral');                           %#ok
    llL2 = logprob(mL1, X, y);                                                      %#ok
    %%
    mL1 = logregDist('nclasses',C);
    mL1 = fit(mL1,'X',X,'y',y,'prior','L1','lambda',0.1);
    pred = predict(mL1,'X',X);                                                      %#ok
end

function demoCrabs()
% Here we fit an L2 regularized logistic regression model to the crabs 
% data set and predict using three methods: MAP plugin approx, Monte
% Carlo approx, and using a closed form approximation to the posterior
% predictive. 
    [Xtrain, ytrain, Xtest, ytest] = makeCrabs;
    sigma2 = 32/5;
    T = chainTransformer({standardizeTransformer(false), kernelTransformer('rbf', sigma2)});
    m = logregDist('nclasses',2, 'transformer', T);
    lambda = 1e-3;
    m = fit(m, 'X', Xtrain, 'y', ytrain, 'lambda', lambda,'prior','l2');
    Pmap   = predict(m,'X',Xtest,'method','plugin');
    Pmc    = predict(m,'X',Xtest,'method','mc');
    Pexact = predict(m,'X',Xtest,'method','integral');
    nerrsMAP   = sum(mode(Pmap)' ~= ytest)
    nerrsMC    = sum(mode(Pmc)' ~= ytest)
    nerrsExact = sum(mode(Pexact)' ~= ytest)      

##### SOURCE END #####
-->
   </body>
</html>